% Created 2020-07-24 Fri 13:55
% Intended LaTeX compiler: pdflatex
\documentclass[letter]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage[margin=1.3in]{geometry}
\setlength{\columnsep}{1cm}
\usepackage{palatino}
\fontfamily{ppl}\selectfont
\usepackage[spanish, es-noindentfirst]{babel}
\renewcommand{\baselinestretch}{1.5}
\usepackage{fancyhdr}
\fancyhf{}
\pagestyle{fancy}
\lhead{\hleft}
\rhead{\hright}
\cfoot{\thepage}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{0pt}
\newcommand{\hleft}{Procesamiento de imágenes}
\newcommand{\hright}{INF 324}
\author{Jesus Rodolfo Izurieta Veliz}
\date{\today}
\title{Clasificación morfológica foliar mediante análisis de imágenes}
\hypersetup{
 pdfauthor={Jesus Rodolfo Izurieta Veliz},
 pdftitle={Clasificación morfológica foliar mediante análisis de imágenes},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.4)}, 
 pdflang={Spanish}}
\begin{document}

\maketitle
\begin{abstract}
El reconocimiento de objetos en imágenes y su clasificación es un problema
ampliamente estudiado en la actualidad, y cuando es necesario aplicarlo, en
general suele pensarse en una solución que implemente redes neuronales y una
gran cantidad de imágenes de prueba para entrenarlas, sin embargo, en algunos
casos específicos, este problema puede tener soluciones más sencillas y rápidas
de implementar. En este caso estudiamos el problema de la clasificación
morfológica de hojas de plantas, sin recurrir al uso de redes neuronales y con un
número reducido de imágenes de prueba.
\end{abstract}

\section{Introducción}
\label{sec:org7011142}
Las redes neuronales son en general una solución eficiente para el problema de
reconocimiento de objetos en imágenes, especialmente en casos en que el objeto
que se quiere obtener de una imagen puede encontrarse en muchas posiciones y
tener una gran cantidad de variaciones, para lo cual es necesaria una gran
cantidad de imágenes de prueba de modo que la red neuronal pueda entrenarse y
responder apropiadamente a una gran cantidad de situaciones. En este caso, el
problema que tratamos de resolver es de una complejidad menor y puede resolverse
por otros medios.

Para clasificar la hoja de una planta, necesitamos una forma de representar su
forma, en este punto nos será útil el método de momentos invariantes de Hu, que
genera valores que describen la forma de un objeto si tenemos su silueta. Los
momentos invariantes de Hu funcionan correctamente en objetos en dos dimensiones
y pueden darnos valores de una imagen que no varían ante transformaciones
simples como escalado o rotación, sin embargo, no nos serán útiles para
transformaciones en tres dimensiones, por lo tanto, su aplicación en este
problema lo convierte en una buena opción, ya que en general, para observar
correctamente la hoja de una planta, suele acomodársela de modo que su forma se
puede observar claramente.

Como un proceso previo a la clasificación de una hoja por la forma que tiene,
tendremos que encontrar la manera de obtener su silueta de la forma más limpia
posible, por lo que utilizamos también técnicas de preprocesado de imágenes como
binarización de imágenes Otsu, que nos permite separar objetos en una imagen
según la disposición del histograma de la imagen.

\subsection{Objetivos}
\label{sec:org6d3ed51}
\subsubsection{Objetivo general}
\label{sec:org392cfd0}
\begin{itemize}
\item Desarrollo de una biblioteca para reconocer y clasificar hojas de plantas en
imágenes sin hacer uso de métodos avanzados de inteligencia artificial como
redes neuronales.
\end{itemize}

\subsubsection{Objetivos específicos}
\label{sec:orgae2bfe3}
\begin{itemize}
\item Desarrollo de una biblioteca que permita una cómoda manipulación de imágenes
para su procesamiento.
\item Expansión de la biblioteca de procesamiento de imágenes implementando
diferentes algoritmos de preprocesamiento de imágenes.
\item Desarrollo de un notebook destallando paso a paso el uso de la biblioteca para
este caso específico.
\end{itemize}

\section{Metodología}
\label{sec:org3bb9ba2}
Este trabajo constituye un análisis descriptivo de la aplicación de diversos
métodos de procesamiento de imágenes, que son aplicados a este problema
específico para comprobar sus resultados. Se parte de la hipótesis inductiva de
que las técnicas usadas nos servirán para conseguir los objetivos de este
proyecto. Estas técnicas que fueron diseñadas para diferentes etapas del
procesamiento de imágenes, pueden aplicarse secuencialmente, ya que cada una
corresponde a una tarea específica que será complementada por las demás.

Seguimos entonces una secuencia de acciones con la finalidad de cumplir el
objetivo de clasificar una hoja en una imagen digital, siguiendo los pasos como
se muestra a continuación:

\begin{center}
\textbf{Binarización de la imagen} \(\rightarrow\) \textbf{Descripción morfológica} \(\rightarrow\) \textbf{Clasificación} \(\rightarrow\) \textbf{Comparación}
\end{center}

Cada uno de estos pasos implementa de forma independiente una técnica de
procesamiento de imágenes, por lo tanto, la imagen de prueba pasará de forma
secuencial por cada uno de estos procesos, siendo la salida de uno, la entrada
del siguiente.

\section{Desarrollo}
\label{sec:org0e09a03}
El proyecto no contará con una interfaz gráfica, sino que constará de un
notebook interactivo de jupyter en el que se podrá apreciar tanto el código
fuente como los resultados de cada paso del proceso de manipulado de las
imágenes. Para esto, se desarrollan las siguientes bibliotecas:

\subsection{Representación de imágenes}
\label{sec:org5c1cd88}
Primeramente definiremos algunos conceptos que utilizaremos en el desarrollo del
proyecto. Para el tratamiento de una imagen digital, la representaremos como una
función de la posición de sus pixeles como sigue:

$$ I:\mathbb N^2 \rightarrow [0, 1] $$
$$ I(x, y) $$

Donde el rango representa el nivel de luminosidad para los pixeles en
coordenadas x e y en el caso de imágenes en escala de grises, para imágenes a
color, tendremos en su lugar una tupla de tres elementos, uno para cada uno de
los colores rojo, verde y azul. En el caso de una imagen digital, estos valores
varían en el rango \([0,255]\in \mathbb N\).

\subsection{Biblioteca Image}
\label{sec:orgf33c558}
La clase imagen es una abstracción básica que nos permitirá acceder y manipular
fácilmente una imagen que puede ser cargada desde un archivo, o puede ser creada
desde un array y posteriormente mostrada en un notebook de jupyter.

\begin{description}
\item[{Load file:}] (Parámetros: ruta) Carga en la instancia la imagen que se
encuentra en la ruta y la convierte en una matriz de tuplas de 3 componentes,
uno por cada color RGB, almacenándola en el atributo \texttt{array} de la clase
imagen, además define otros atributos como las dimensiones de la imagen.

\item[{Load array:}] (Parámetros: array) Almacena una matriz en el atributo \texttt{array}
de la imagen, la matriz debe ser una matriz de tuplas de tres valores.

\item[{Show:}] Retorna un objeto PIL.Image.Image que permite visualizar la imagen en
un notebook de jupyter o almacenarla como un archivo.

\item[{I:}] (Parámetros: x, y) Representa la función \(I(x, y)\) definida previamente,
retorna los píxeles en la posición x, y como una tupla de 3 valores.

\item[{I normal:}] (Parámetros: x, y) Igual que I() pero en lugar de retornar
valores en el rango [0, 255] normaliza los valores al rango [0, 1].

\item[{I m:}] (Parámetros: x, y, color) Igual que I(), pero retorna un único valor
definido por el parámetro \texttt{color}, 0 para rojo, 1 para verde y 2 para azul, el
valor por defecto es rojo si no se define el parámetro color.

\item[{I mnormal:}] (Parámetros: x, y, color) Igual que I\textsubscript{m}() pero con valores
normalizados en el rango [0, 1]

\item[{Iterator:}] Retorna un iterador de tuplas x, y que facilita iteraciones
sobre cada píxel de la imagen.

\item[{Map over:}] (Parámetros: func) Permite sobreescribir píxeles mediante una
función que se envía como parámetro, la función recibirá una tupla de 3
valores y debe devolver una tupla de 3 valores. Esta función nos permitirá
recorrer la totalidad de la imagen aplicando en cada pixel la función \texttt{func},
por ejemplo el código \texttt{img.map\_over(lambda x, y, z: (x, x, x))} ejecutado
sobre una imagen img2, permitirá cambiar el valor de cada canal por su valor
rojo, lo que convertirá a la imagen a blanco y negro.
\end{description}

\subsection{Preprocesamiento}
\label{sec:orga2a7e6d}

\subsubsection{Reducción de ruido}
\label{sec:org0ec6b4d}
\subsubsection{Corrección de iluminación}
\label{sec:org26091c3}

\subsubsection{Segmentación}
\label{sec:orgff7a10d}

\subsection{Procesamiento}
\label{sec:orga936326}
\subsubsection{Filtrado Otsu}
\label{sec:org3076526}
\subsubsection{Momentos de Hu}
\label{sec:orgf68f8cc}
Para obtener un valor propio de la forma geométrica de un objeto en una imagen,
usaremos momentos de Hu o momentos invariantes, un algoritmo que nos permite
obtener un conjunto de valores asignados a una matriz según la disposición que
esta tenga, sin variar en cuanto a transformaciones como escalado o rotación.

Los momentos de orden \((p+q)\) en dos dimensiones sobre una función de
distribución \(p(x, y)\) continua, son calculados mediante integrales de Riemman
como sigue:

$$
m_{pq} =  \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x^p y^q p(x, y)\,dx\,dy \quad p, q = 0, 1, 2, ...
$$

Sin embargo, en el caso del tratamiento de imágenes, esta será la función
discreta \(I(x, y)\) que describa nuestra imagen en función de la posición de sus
pixeles, por lo que la definición de momentos usada será:

$$
m_{pq} = \sum_x \sum_y x^p y^q I(x, y)
$$

\subsubsection{Datos de comparación}
\label{sec:org8eb95a7}

\subsubsection{Comparación y clasificación}
\label{sec:org0ec4f85}

\subsection{Resultados}
\label{sec:orgfe45e77}
\subsection{Evaluación}
\label{sec:org57d28c2}
\section{Conclusiones}
\label{sec:org05725fb}

\section{Referencias}
\label{sec:orgd5249b6}

\section{Anexos}
\label{sec:org71c7c6a}
\subsection{Código fuente}
\label{sec:orgfd01262}
\subsubsection{Biblioteca Imagen}
\label{sec:org01aef9b}
\begin{verbatim}
#!/usr/bin/env python3
import matplotlib.image as plt_img
import numpy as np
from PIL import Image as pil_image
from functools import reduce
from math import sqrt


class Image:

    def __init__(self):
        self.route = "."
        self.image = None
        self.array = None
        self.height, self.width, self.dat = (0,0,0)

    def load_file(self, route):
        self.route = route
        self.image = plt_img.imread(route)
        self.array = self.image.tolist()
        self.height, self.width, self.dat = self.image.shape

    def load_array(self, array):
        self.array = array
        self.height = len(array)
        self.width = len(array[0])

    def I(self, x, y):
        """ Devuelve rgb en x, y """
        return tuple(self.array[x][y])

    def I_m(self, x, y, color=0):
        """ Devuelve un color de x, y """
        triple = self.array[x][y]
        return triple[color]

    def I_normal(self, x, y):
        """ Devuelve rgb en [0, 1] """
        (i, j, k) = self.I(x, y)
        return (i/255, j/255, k/255)

    def I_mnormal(self, x, y, color=0):
        """ Devuelve color en [0, 1] """
        i = self.I_m(x, y, color)
        return i/255

    def show(self, route=None):
        if route:
            self.route = route
        image_arr = np.asarray(self.array, dtype="uint8")
        img_file = pil_image.fromarray(image_arr, 'RGB')
        return img_file

    def iterator(self):
        for i in range(self.height):
            for j in range(self.width):
                yield (i,j)

    def map_over(self, func):
        """ Ejecución de func sobre cada pixel """
        for x, y in self.iterator():
            self.array[x][y] = func(*self.I(x, y))

    def crop(self, x1, y1, x2, y2):
        cropped_array = []
        for i in range(y1, y2):
            arr = []
            for j in range(x1, x2):
                arr.append(self.I(i, j))
            cropped_array.append(arr)
        cropped_image = Image()
        cropped_image.load_array(cropped_array)
        return cropped_image


    def hu_moments(self):
        """ Primeros dos momentos de Hu """
        def moment_pq(p, q):
            """ Momentos geométricos """
            sum = 0
            for x, y in self.iterator():
                sum += x**p * y**q * self.I_mnormal(x, y)
            return sum

        m00 = moment_pq(0, 0)
        m01 = moment_pq(0, 1)
        m11 = moment_pq(1, 1)
        m10 = moment_pq(1, 0)
        m20 = moment_pq(2, 0)
        m02 = moment_pq(0, 2)

        def central_moment_20(a, b, c):
            """ Momentos centrales """
            return (a-(b**2/c))/(c**2)

        n20 = central_moment_20(m20, m10, m00)
        n02 = central_moment_20(m02, m01, m00)
        n11 = central_moment_20(m11, sqrt(m10*m01), m00)

        self.X, self.Y = (n20+n02, (n20-n02)**2+4*(n11**2))

        return (self.X, self.Y)
\end{verbatim}
\subsection{Pruebas y resultados}
\label{sec:org9c0058c}
Contenido de esta wea
\subsubsection{Momentos invariantes de Hu}
\label{sec:orgcabea5c}
Contenido de esta wea
\begin{enumerate}
\item nippa1
\label{sec:org9f7f626}
Contenido de esta wea
\begin{enumerate}
\item nippa2
\label{sec:org832cd46}
Contenido de esta wea
\end{enumerate}
\end{enumerate}
\end{document}
