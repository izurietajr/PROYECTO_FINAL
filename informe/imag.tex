% Created 2020-07-23 Thu 23:49
% Intended LaTeX compiler: pdflatex
\documentclass[letter]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage[margin=1.3in]{geometry}
\setlength{\columnsep}{1cm}
\usepackage{palatino}
\fontfamily{ppl}\selectfont
\usepackage[spanish, es-noindentfirst]{babel}
\renewcommand{\baselinestretch}{1.5}
\usepackage{fancyhdr}
\fancyhf{}
\pagestyle{fancy}
\lhead{\hleft}
\rhead{\hright}
\cfoot{\thepage}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{0pt}
\newcommand{\hleft}{Procesamiento de imágenes}
\newcommand{\hright}{INF 324}
\author{Jesus Rodolfo Izurieta Veliz}
\date{\today}
\title{Clasificación automática de tipos de hojas en imágenes}
\hypersetup{
 pdfauthor={Jesus Rodolfo Izurieta Veliz},
 pdftitle={Clasificación automática de tipos de hojas en imágenes},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.4)}, 
 pdflang={Spanish}}
\begin{document}

\maketitle
\begin{abstract}
El reconocimiento de objetos en imágenes y su clasificación es un problema
ampliamente estudiado en la actualidad, y cuando es necesario aplicarlo, en
general suele pensarse en una solución que implemente redes neuronales y una
gran cantidad de imágenes de prueba para entrenarlas, sin embargo, en algunos
casos específicos, este problema puede tener soluciones más sencillas y rápidas
de implementar. En este caso estudiaremos el problema de la clasificación
automática de tipos de hojas, sin recurrir al uso de redes neuronales y con un
número reducido de imágenes de prueba.
\end{abstract}

\section{Introducción}
\label{sec:orgfcda02d}
Las redes neuronales son en general una solución eficiente para el problema de
reconocimiento de objetos en imágenes, especialmente en casos en que el objeto
que se quiere obtener de una imagen puede encontrarse en muchas posiciones y
tener una gran cantidad de variaciones, para lo cual es necesaria una gran
cantidad de imágenes de prueba de modo que la red neuronal pueda entrenarse y
responder apropiadamente a una gran cantidad de situaciones. En este caso, el
problema que tratamos de resolver es de una complejidad menor y puede resolverse
por otros medios.

Para clasificar la hoja de una planta, necesitamos una forma de representar su
forma, en este punto nos será útil el método de momentos invariantes de Hu, que
genera valores que describen la forma de un objeto si tenemos su silueta. Los
momentos invariantes de Hu funcionan correctamente en objetos en dos dimensiones
y pueden darnos valores de una imagen que no varían ante transformaciones
simples como escalado o rotación, sin embargo, no nos serán útiles para
transformaciones en tres dimensiones, por lo tanto, su aplicación en este
problema lo convierte en una buena opción, ya que en general, para observar
correctamente la hoja de una planta, suele acomodársela de modo que su forma se
puede observar claramente.

Como un proceso previo a la clasificación de una hoja por la forma que tiene,
tendremos que encontrar la manera de obtener su silueta de la forma más limpia
posible, por lo que utilizamos también técnicas de preprocesado de imágenes como
binarización de imágenes Otsu, que nos permite separar objetos en una imagen
según la disposición del histograma de la imagen.

\section{Objetivos}
\label{sec:orgc99e6ae}
\subsection{Objetivo general}
\label{sec:orgf501058}
\begin{itemize}
\item Desarrollo de una biblioteca para reconocer y clasificar hojas de plantas en
imágenes sin hacer uso de métodos avanzados de inteligencia artificial como
redes neuronales.
\end{itemize}

\subsection{Objetivos específicos}
\label{sec:orgc4911ca}
\begin{itemize}
\item Desarrollo de una biblioteca que permita una cómoda manipulación de imágenes
para su procesamiento.
\item Expansión de la biblioteca de procesamiento de imágenes implementando
diferentes algoritmos de preprocesamiento de imágenes.
\item Desarrollo de un notebook destallando paso a paso el uso de la biblioteca para
este caso específico.
\end{itemize}

\section{Fundamentos teóricos}
\label{sec:orge0a9b78}
Primeramente definiremos algunos conceptos que utilizaremos en el desarrollo del
proyecto. Para el tratamiento de una imagen digital, la representaremos como una
función de la posición de sus pixeles como sigue:

$$ I:\mathbb N^2 \rightarrow [0, 1] $$
$$ I(x, y) $$

Donde el rango representa el nivel de luminosidad para los pixeles en
coordenadas x e y en el caso de imágenes en escala de grises, para imágenes a
color, tendremos en su lugar una tupla de tres elementos, uno para cada uno de
los colores rojo, verde y azul. En el caso de una imagen digital, estos valores
varían en el rango \([0,255]\in \mathbb N\).

\section{Desarrollo}
\label{sec:orge37e224}
El proyecto no contará con una interfaz gráfica, sino que constará de un
notebook interactivo de jupyter en el que se podrá apreciar tanto el código
fuente como los resultados de cada paso del proceso de manipulado de las
imágenes. Para esto, se desarrollan las siguientes bibliotecas:

\subsection{Clase Image}
\label{sec:org8d4e6f3}
La clase imagen es una abstracción básica que nos permitirá acceder y manipular
fácilmente una imagen que puede ser cargada desde un archivo, o puede ser creada
desde un array y posteriormente mostrada en un notebook de jupyter.

\begin{description}
\item[{Load file:}] (Parámetros: ruta) Carga en la instancia la imagen que se
encuentra en la ruta y la convierte en una matriz de tuplas de 3 componentes,
uno por cada color RGB, almacenándola en el atributo \texttt{array} de la clase
imagen, además define otros atributos como las dimensiones de la imagen.

\item[{Load array:}] (Parámetros: array) Almacena una matriz en el atributo \texttt{array}
de la imagen, la matriz debe ser una matriz de tuplas de tres valores.

\item[{Show:}] Retorna un objeto PIL.Image.Image que permite visualizar la imagen en
un notebook de jupyter o almacenarla como un archivo.

\item[{I:}] (Parámetros: x, y) Representa la función \(I(x, y)\) definida previamente,
retorna los píxeles en la posición x, y como una tupla de 3 valores.

\item[{I normal:}] (Parámetros: x, y) Igual que I() pero en lugar de retornar
valores en el rango [0, 255] normaliza los valores al rango [0, 1].

\item[{I m:}] (Parámetros: x, y, color) Igual que I(), pero retorna un único valor
definido por el parámetro \texttt{color}, 0 para rojo, 1 para verde y 2 para azul, el
valor por defecto es rojo si no se define el parámetro color.

\item[{I mnormal:}] (Parámetros: x, y, color) Igual que I\textsubscript{m}() pero con valores
normalizados en el rango [0, 1]

\item[{Iterator:}] Retorna un iterador de tuplas x, y que facilita iteraciones
sobre cada píxel de la imagen.

\item[{Map over:}] (Parámetros: func) Permite sobreescribir píxeles mediante una
función que se envía como parámetro, la función recibirá una tupla de 3
valores y debe devolver una tupla de 3 valores. Esta función nos permitirá
recorrer la totalidad de la imagen aplicando en cada pixel la función \texttt{func},
por ejemplo el código \texttt{img.map\_over(lambda x, y, z: (x, x, x))} ejecutado
sobre una imagen img2, permitirá cambiar el valor de cada canal por su valor
rojo, lo que convertirá a la imagen a blanco y negro.
\end{description}

\subsection{Preprocesamiento}
\label{sec:orgdcdf52f}

\subsubsection{Reducción de ruido}
\label{sec:orgfb7f1ff}
\subsubsection{Corrección de iluminación}
\label{sec:orgba892a6}

\subsection{Segmentación}
\label{sec:org60b32e5}

\subsection{Procesamiento}
\label{sec:org2ec38e4}
\subsubsection{Momentos de Hu}
\label{sec:org3cba0a5}
Para obtener un valor propio de la forma geométrica de un objeto en una imagen,
usaremos momentos de Hu o momentos invariantes, un algoritmo que nos permite
obtener un conjunto de valores asignados a una matriz según la disposición que
esta tenga, sin variar en cuanto a transformaciones como escalado o rotación.

Los momentos de orden \((p+q)\) en dos dimensiones sobre una función de
distribución \(p(x, y)\) continua, son calculados mediante integrales de Riemman
como sigue:

$$
m_{pq} =  \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x^p y^q p(x, y)\,dx\,dy \quad p, q = 0, 1, 2, ...
$$

Sin embargo, en el caso del tratamiento de imágenes, esta será la función
discreta \(I(x, y)\) que describa nuestra imagen en función de la posición de sus
pixeles, por lo que la definición de momentos usada será:

$$
m_{pq} = \sum_x \sum_y x^p y^q I(x, y)
$$

\subsubsection{Extracción de rasgos}
\label{sec:orgdc371b9}

\subsubsection{Datos de comparación}
\label{sec:org734cd57}

\subsubsection{Comparación y clasificación}
\label{sec:org9580a2d}

\section{Pruebas}
\label{sec:orgb5b59c1}

\section{Conclusiones}
\label{sec:org92e0ac1}

\section{Referencias}
\label{sec:org7386212}

\section{Anexos}
\label{sec:orgbe8f03c}
\subsection{Código fuente}
\label{sec:orgc5034aa}
\subsubsection{Clase Imagen}
\label{sec:orgf310613}
\subsubsection{Filtrado ADF}
\label{sec:org8b4a4f9}
\subsubsection{Filtrado Top-Hat}
\label{sec:org1996111}
\subsubsection{Filtrado Otsu}
\label{sec:org3218226}
\subsubsection{Momentos de Hu}
\label{sec:org9c44482}
Obtención de momentos geométricos de orden \(p+q\), \(m_{pq} = \sum_x \sum_y x^p y^q I(x, y)\).

\begin{verbatim}
def m_pq():
   
\end{verbatim}

\subsubsection{KNN}
\label{sec:orgeff09ac}

\subsection{Resultados}
\label{sec:orgc643ca9}
\end{document}
