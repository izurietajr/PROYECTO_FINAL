#+TITLE: Clasificación morfológica foliar mediante procesamiento de imágenes
#+include: ~/org/templates/tarea.org
#+latex_header: \newcommand{\hleft}{Clasificación morfológica foliar}
#+latex_header: \newcommand{\hright}{INF 324}
#+author: Jesus Izurieta Veliz \quad Cristian Aquino Apaza
#+BIBLIOGRAPHY: report apalike


\begin{abstract}
El reconocimiento de objetos en imágenes y su clasificación es un problema
ampliamente estudiado en la actualidad, y cuando es necesario aplicarlo, en
general suele pensarse en una solución que implemente redes neuronales y una
gran cantidad de imágenes de prueba para entrenarlas, sin embargo, en algunos
casos específicos, este problema puede tener soluciones más sencillas y rápidas
de implementar. En este caso estudiamos el problema de la clasificación
morfológica de hojas de plantas, sin recurrir al uso de redes neuronales y con un
número reducido de imágenes de prueba.
\end{abstract}


* Introducción
Para clasificar la hoja de una planta, necesitamos una forma de representar su
forma, en este punto nos será útil el método de momentos invariantes de Hu, que
genera valores que describen la forma de un objeto si tenemos su silueta. Los
momentos invariantes de Hu funcionan correctamente en objetos en dos dimensiones
\cite{Hu1962} y pueden darnos valores de una imagen que no varían ante
transformaciones simples como escalado o rotación, sin embargo, no nos serán
útiles para transformaciones en tres dimensiones, por lo tanto, su aplicación en
este problema lo convierte en una buena opción, ya que en general, para observar
correctamente la hoja de una planta, suele acomodársela de modo que su forma se
puede observar claramente su forma.

Las redes neuronales son en general una solución eficiente para el problema de
reconocimiento de objetos en imágenes, especialmente en casos en que el objeto
que se quiere obtener de una imagen puede encontrarse en muchas posiciones y
tener una gran cantidad de variaciones, para lo cual es necesaria una gran
cantidad de imágenes de prueba de modo que la red neuronal pueda entrenarse y
responder apropiadamente a una gran cantidad de situaciones. En este caso, el
problema que tratamos de resolver es de una complejidad menor y puede resolverse
por otros medios.

Como un proceso previo a la clasificación de una hoja por la forma que tiene,
tendremos que encontrar la manera de obtener su silueta de la forma más limpia
posible, por lo que utilizamos también técnicas de preprocesado de imágenes como
binarización de imágenes Otsu, que nos permite separar objetos en una imagen
según la disposición del histograma de la imagen.

** Objetivos
*** Objetivo general
- Desarrollo de una biblioteca para reconocer y clasificar hojas de plantas en
  imágenes sin hacer uso de métodos avanzados de inteligencia artificial como
  redes neuronales.

*** Objetivos específicos
- Desarrollo de una biblioteca que permita una cómoda manipulación de imágenes
  para su procesamiento.
- Expansión de la biblioteca de procesamiento de imágenes implementando
  diferentes algoritmos de preprocesamiento de imágenes.
- Desarrollo de un notebook destallando paso a paso el uso de la biblioteca para
  este caso específico.

* Metodología
Este trabajo constituye un análisis descriptivo de la aplicación de diversos
métodos de procesamiento de imágenes, que son aplicados a este problema
específico para comprobar sus resultados. Se parte de la hipótesis inductiva de
que las técnicas usadas nos servirán para conseguir los objetivos de este
proyecto. Estas técnicas que fueron diseñadas para diferentes etapas del
procesamiento de imágenes, pueden aplicarse secuencialmente, ya que cada una
corresponde a una tarea específica que será complementada por las demás.

Seguimos entonces una secuencia de acciones con la finalidad de cumplir el
objetivo de clasificar una hoja en una imagen digital, siguiendo los pasos como
se muestra a continuación:

#+begin_center
*Binarización de la imagen* \rightarrow *Descripción morfológica* \rightarrow
 *Clasificación* \rightarrow *Comparación*
#+end_center

Cada uno de estos pasos implementa de forma independiente una técnica de
procesamiento de imágenes, por lo tanto, la imagen de prueba pasará de forma
secuencial por cada uno de estos procesos, siendo la salida de uno, la entrada
del siguiente.

El proceso de binarización de una imagen nos permite separar los objetos de
interés de una fotografía, para esto usamos la técnica de filtrado Otsu, que
analiza el histograma de la imagen encontrando un punto medio desde el cual
podremos separar grupos de objetos por colores. Para la descripción morfológica,
usamos momentos invariantes de Hu, una técnica que permite describir la forma de
una imagen mediante valores numéricos que no varían ante transformaciones
simples como escalado o rotación. Se analizan estadísticamente dos momentos de
Hu ($\phi_1$ y $\phi_2$) para cada tipo de hoja de un conjunto de imágenes de
prueba, con la finalidad de poder determinar áreas en el plano $\phi_1$, $\phi_2$
en que se encuentre cada tipo de hoja. Finalmente comparamos la posición en el
plano de los momentos obtenidos de una imagen para poder clasificarla en uno de
estos grupos con cierta probabilidad de pertenencia según su distancia al
centro de gravedad de cada conjunto.

* Morfología foliar
La morfología foliar es una disciplina que clasifica las hojas de las plantas
por la forma que tienen, pueden clasificarse según diferentes atributos como la
forma del limbo, tipos de ápices foliares, tipos de bases, tipos de vernación y
nerviación y si son o no compuestas.

En la figura [[fig:leaf]] se pueden apreciar las diferentes partes por las que las
hojas son clasificadas. En este trabajo, por simplicidad, tomamos en cuenta sólo
la clasificación por la forma del limbo en hojas simples, de modo que
distinguiremos las siguientes formas:

- lanceolada
- flabelada
- acumitada
- orbicular
- romboide
- ovada
- astada
- palmeada
- sagitada

#+caption: Partes de una hoja.
#+name: fig:leaf
[[./images/leaf-parts.jpg]]

* Desarrollo
Para este proyecto desarrollamos una librería que nos ayude a manipular una
imagen, proveyendo las funciones de convolución, modificación píxel a píxel,
histograma, cargado de imágenes y la capacidad de convertirlas en matrices y
viceversa, además de implementar los filtros necesarios para clasificar
imágenes.

El proyecto no contará con una interfaz gráfica, sino que constará de un
notebook interactivo de jupyter en el que se podrá apreciar tanto el código
fuente como los resultados de cada paso del proceso de manipulado de las
imágenes.

** Representación de imágenes
Primeramente definiremos algunos conceptos que utilizaremos en el desarrollo del
proyecto. Para el tratamiento de una imagen digital, la representaremos como una
función de la posición de sus pixeles como sigue:

$$ I:\mathbb N^2 \rightarrow [0, 1] $$
$$ I(x, y) $$

Donde el rango representa el nivel de luminosidad para los pixeles en
coordenadas x e y en el caso de imágenes en escala de grises, para imágenes a
color, tendremos en su lugar una tupla de tres elementos, uno para cada uno de
los colores rojo, verde y azul. En el caso de una imagen digital, estos valores
varían en el rango $[0,255]\in \mathbb N$.

** Manipulación de imágenes
La clase imagen es una abstracción básica que nos permitirá acceder y manipular
fácilmente una imagen que puede ser cargada desde un archivo, o puede ser creada
desde un array y posteriormente mostrada en un notebook de jupyter.

- Load file: :: (Parámetros: ruta) Carga en la instancia la imagen que se
  encuentra en la ruta y la convierte en una matriz de tuplas de 3 componentes,
  uno por cada color RGB, almacenándola en el atributo =array= de la clase
  imagen, además define otros atributos como las dimensiones de la imagen.

- Load array: :: (Parámetros: array) Almacena una matriz en el atributo =array=
  de la imagen, la matriz debe ser contener tuplas de tres valores que se
  encuentren entre 0 y 255.

- Show: :: Retorna un objeto PIL.Image.Image que permite visualizar la imagen en
  un notebook de jupyter o almacenarla como un archivo.

- I: :: (Parámetros: x, y) Representa la función $I(x, y)$ definida previamente,
  retorna los píxeles en la posición x, y como una tupla de 3 valores.

- I normal: :: (Parámetros: x, y) Igual que I() pero en lugar de retornar
  valores en el rango [0, 255] normaliza los valores al rango [0, 1].

- I m: :: (Parámetros: x, y, color) Igual que I(), pero retorna un único valor
  definido por el parámetro =color=, 0 para rojo, 1 para verde y 2 para azul, el
  valor por defecto es rojo si no se define el parámetro color.

- I mnormal: :: (Parámetros: x, y, color) Igual que I_m() pero con valores
  normalizados en el rango $[0, 1]$.

- Iterator: ::  Retorna un iterador de tuplas x, y que facilita iteraciones
  sobre cada píxel de la imagen.

- Map over: :: (Parámetros: func) Permite sobreescribir píxeles mediante una
  función que se envía como parámetro, la función recibirá una tupla de 3
  valores y debe devolver una tupla de 3 valores. Esta función nos permitirá
  recorrer la totalidad de la imagen aplicando en cada pixel la función =func=,
  por ejemplo el código =img.map_over(lambda x, y, z: (x, x, x))= ejecutado
  sobre una imagen img2, permitirá cambiar el valor de cada canal por su valor
  rojo, lo que convertirá a la imagen a blanco y negro.

** Procesamiento
El procesamiento de una imagen para su posterior clasificación, consiste en la
separación de la parte de interés de la imagen (en este caso la hoja), de modo
que pueda apreciarse su forma sin objetos de fondo, esto se realizará usando el
método de filtrado de Otsu, posteriormente se obtendrán los momentos invariantes
de Hu de la imagen, que describen la forma que tiene la hoja.

*** Segmentación de umbral de Otsu
La segmentación de una imagen por el método de Otsu consiste en separar un
objeto en una imagen de otros objetos que no nos son de interés, para esto
trabajamos sobre el histograma de una imagen, que representa la frecuencia en
que aparecen los colores en una imagen, un ejemplo de histograma separado por
colores rojo, verde y azul se puede ver en la figura [[fig:histo1]]

#+caption: Histogramas por color en una imagen.
#+name: fig:histo1
[[./images/histogram1.png]]

El problema de la segmentación de objetos en una imagen es un problema de
minimización, cuando encontramos una imagen en que el objeto de interés tiene un
color diferente al color de fondo, el histograma de la imagen toma una
disposición bimodal \cite{Smith1979} como se muestra en la figura [[fig:histo2]], trabajaremos con
imágenes convertidas a blanco y negro para tener un único histograma en el que
realizar la separación.

#+caption: Histograma de la imagen en blanco y negro, se puede apreciar un valle entre los valores 50 a 100 que separa dos grupos de mayor frecuencia.
#+name: fig:histo2
[[./images/histogram2.png]]

Como se ve en la imagen [[fig:histo2]], el histograma bimodal tiene una clara
reparación en la que podemos separar dos grupos de colores, el punto de
separación se encontrará en el punto mínimo de ese valle, una vez encontrado
este punto, podemos binarizar \cite{Noh2005} la imagen separándola por umbrales, de modo que el
resultado es algo similar a la figura [[fig:binaryleaf]].

#+attr_latex: :width 5cm
#+caption: Imagen binarizada tomando el valor 75 para separar los umbrales de color.
#+name: fig:binaryleaf
[[./images/binaryleaf.png]]

La finalidad del método de Otsu es encontrar este punto mínimo en que la
separación de umbrales de color es óptima, esto se consigue encontrando el valor
$t$ que minimiza la función:

#+name: eqn:sigma
\begin{equation}
\sigma_w^2(t) =  q_1(t)\sigma_1^2(t) + q_2(t)\sigma_2^2(t)
\end{equation}

En esta función $t$ es la variable que debe ser minimizada y representa el punto
medio que dividirá los dos umbrales. Las funciones $q_1(t)$ y $q_2(t)$
representan la probabilidad de cada grupo se definen como sigue:

$$ q_1(t) = \sum_{i=1}^t P(i), \quad q_2(t) = \sum_{i=t+1}^I P(i) $$

Para obtener estos valores, necesitamos normalizar nuesto histograma de modo que
su área sea igual a 1 y de este modo se convierta en una función de probabilidad
\cite{Smith1979} para cada valor de píxel, esta función normalizada es $P(i)$,
lo que hacen las funciones $q_1(t)$ y $q_2(t)$ es separar esta función en dos
partes, una de 0 a t y otra de t+1 hasta I que es en este caso es 255.
Seguidamente obtenemos la media de ambas clases:

$$ \mu_1(t) = \sum_{i=1}^t \frac{i P(i)}{q_1(t)} , \quad \mu_2(t) = \sum_{i=t+1}^I \frac{i P(i)}{q_2(t)} $$

Y después de obtener la media de ambas clases, calculamos su varianza.

$$ \sigma_1^2(t) = \sum_{i=1}^t [i-\mu_1(t)]^2 \frac{P(i)}{q_1(t)} , \quad \sigma_2^2(t) = \sum_{i=t+1}^I [i-\mu_2(t)]^2 \frac{P(i)}{q_2(t)} $$

Con las funciones de probabilidad $q_1(t)$ y $q_2(t)$ y con la varianza de
estas, podemos obtener la ecuación [[eqn:sigma]], que representa la varianza de
pesos por clase[fn:wightvariance]. Tendremos ahora que minimizar esta función,
para esto, la solución más sencilla consiste en evaluar esta función para cada
valor de 0 a 255 y seleccionar el valor mínimo para t, ya que
computacionalmente, el cálculo de $\sigma_w^2(t)$ para cada t no tiene mucha
complejidad.

Los métodos =minimum_otsu= y =binarize= implementan esta técnica, =minimum_otsu=
se ocupa de calcular el valor t que minimiza la varianza, y =binarize= cambia
los valores de los pixeles de la imagen, dependiendo si se encuentran a la
derecha o izquierda del valor t, dando como resultado, una imagen como la figura
[[fig:binaryleaf]]. El código puede encontrarse en la sección [[Anexos][Anexos]].

*** Momentos invariantes de Hu
Para obtener un valor propio de la forma geométrica de un objeto en una imagen,
usaremos momentos invariantes de Hu, un conjunto de valores calculados en base a
la imagen, que nos permiten describir su forma y que permanecen constantes aún
cuando se aplican sobre la imagen transformaciones como rotación, reflexión o
escalado \cite{Hu1962}.

Los momentos de orden $(p+q)$ en dos dimensiones sobre una función de
distribución $p(x, y)$ continua, son calculados mediante integrales de Riemman
como sigue:

$$ m_{pq} =  \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x^p y^q p(x, y)\,dx\,dy \quad p, q = 0, 1, 2, ... $$

En este caso, usaremos momentos centrales que se definen como sigue para una
función $p(x, y)$ continua:

$$ \mu_{pq} = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} (x-\bar x)^p (y-\bar y)^q p(x, y)\, d(x-\bar x)\,d(y-\bar y) $$

donde:

$$ \bar x = \frac{m_{10}}{m_{00}}, \quad \bar y = \frac{m_{01}}{m_{00}} $$

son las coordenadas del centroide[fn:centroide] del objeto en la imagen.

Sin embargo, ya que se trata de una imagen digital en que usamos valores
discretos, calcularemos los momentos centrales con las ecuaciones:

$$
\mu_{pq} = \sum_x \sum_y x^p y^q I(x, y)
$$

$$ n_{pq} = \frac{\mu_{pq}}{\mu_{00}^r}, \quad r=\frac{p+q}{2}+1 $$

Con estas ecuaciones podremos calcular los momentos invariantes que usaremos en
este proyecto. Nos limitamos a usar los primeros dos momentos invariantes de Hu,
ya que nos son suficientes en este caso.

$$ \phi_1 = n_{20} + n_{02}, \quad \phi_2 = (n_{20} + n_{02})^2 + 4n_{11}^2 $$

Estos dos valores representan la extensión y la estrechez del objeto
respectivamente[fn:spread-slenderness].
Este proceso es implementado en el método =hu_moments= de la clase image,
retornando los dos primeros momentos.

#+caption: Imagen de una estrella con transformaciones, primero la imagen original, luego escalada, luego rotada y finalmente escalada y deformada.
#+name: fig:stars
[[./images/stars.png]]

Probando el algoritmo con las tres imágenes de ejemplo de la figura [[fig:stars]] obtenemos
los valores:

|          |            $\phi_1$ |              $\phi_2$ |
|----------+---------------------+-----------------------|
| Imagen 1 |  0.2162437035817964 |  7.15421105863606e-10 |
| Imagen 2 | 0.21685851808651274 | 4.778874641818779e-09 |
| Imagen 3 |  0.2162170223369867 | 6.370439738565976e-09 |
| Imagen 4 | 0.23248362379752913 |  0.007129570200901847 |

Los valores de $\phi_1$ y $\phi_2$ para las primeras tres transformaciones son
muy similares debido a que se trata de la misma forma en diferentes tamaños y
posiciones, mientras que los momentos de la imagen 4 varían notablemente por
estar deformada.

** Datos de comparación
Para obtener datos de comparación, recolectamos algunas imágenes de ejemplo que
nos servirán para tener valores iniciales de momentos invariantes para
diferentes tipos de hojas (Figura [[fig:testleaves]]).

#+caption: Imágenes de prueba de los tipos de hojas que clasificamos.
#+name: fig:testleaves
[[./images/leaves.png]]

Aplicando las técnicas de filtrado de Otsu y momentso invariantes de Hu, obtenemos los valores de $\phi_1$ y $\phi_2$ para las imágenes de prueba.

#+caption: Momentos invariantes obtenidos de las imágenes de ejemplo.
|--------------+----------------------+---------------------|
| Tipo de hoja |             $\phi_1$ |            $\phi_2$ |
|--------------+----------------------+---------------------|
| Lanceolada   |  0.08241080043135868 |  0.3999693426853134 |
| Flabelada    |  0.02452288351987129 |  0.3207811493752293 |
| Acumitada    |  0.05055337469475332 |  0.3610066090495226 |
| Orbicular    | 0.020097387958003515 | 0.31300964425473893 |
| Romboide     |  0.04190473916737033 | 0.34816780188557916 |
| Ovada        | 0.023285971562215516 | 0.35150337160513034 |
| Astada       | 0.033590539033761975 |  0.3190729877395031 |
| Palmeada     | 0.012872876070329099 |  0.2860389435844065 |
| Sagitada     |  0.06468482190387434 |  0.4117437381830096 |
|--------------+----------------------+---------------------|

En la figura [[fig:dist]] podemos ver cómo se distribuyen los momentos de las imágenes en el plano.

#+attr_latex: :width 10cm
#+caption: Distribución de momentos invariantes por tipo de hoja en el plano $\phi_1, \phi_2$.
#+name: fig:dist
[[./images/moments.jpg]]

** Comparación y clasificación
Para comparar los resultados de momentos de una imagen con valores obtenidos
previamente, el algoritmo ideal a ser utilizado es K-nearest neighbors.

*** Algoritmo K-Nearest Neighbors
K-Nearest Neighbors, o KNN para abreviar, es uno de los algoritmos de
aprendizaje automático más simples y se utiliza en una amplia gama de
instituciones. KNN es un algoritmo de aprendizaje lento no paramétrico. Cuando
decimos que una técnica no es paramétrica, significa que no hace suposiciones
sobre los datos subyacentes. En otras palabras, realiza su selección en función
de la proximidad a otros puntos de datos, independientemente de la
característica que representen los valores numéricos.Ser un vago algoritmo de
aprendizaje implica que hay poca o ninguna fase de entrenamiento. Por lo tanto,
podemos clasificar inmediatamente los nuevos puntos de datos a medida que se
presentan.

Algunos pros y contras de KNN

**** Pros :
- No hay suposiciones sobre los datos.
- Algoritmo simple - fácil de entender
- Se puede usar para clasificación y regresión

**** Contras :
- Requisito de memoria alta: todos los datos de entrenamiento deben estar
  presentes en la memoria para calcular los K vecinos más cercanos
- Sensible a características irrelevantes
- Sensible a la escala de los datos ya que estamos calculando la distancia a los
  puntos K más cercanos.

** Ejecución y resultados
Ahora procedemos a utilizar la biblioteca desarrollada con una imagen de ejemplo
que podremos clasificar. Primeramente importamos las bibliotecas que usaremos.

#+BEGIN_SRC python
from image import Image
import matplotlib.pyplot as plt
#+END_SRC

Cargaremos las imágenes de prueba que mostramos previamente en la figura
[[fig:testleaves]].

#+BEGIN_SRC python
lanceolada = "./testimages/leafs/lanceolada.jpg"
flabelada = "./testimages/leafs/flabelada.jpg"
acumitada = "./testimages/leafs/acumitada.jpg"
orbicular = "./testimages/leafs/orbicular.jpg"
romboide = "./testimages/leafs/romboide.jpg"
ovada = "./testimages/leafs/ovada.jpg"
astada = "./testimages/leafs/astada.jpg"
palmeada = "./testimages/leafs/palmeada.jpg"
sagitada = "./testimages/leafs/sagitada.jpg"

leafs =[
    lanceolada, flabelada, acumitada, orbicular,
    romboide, ovada, astada, palmeada, sagitada
]
#+END_SRC

Podemos abrir una de estas imágenes para comprobar que se hayan cargado correctamente:

#+BEGIN_SRC python
ll = Image()
ll.load_file(flabelada)
ll.show()
#+END_SRC

Nos mostrará la imagen:

#+attr_latex: :width 5cm
[[./images/show.png]]

A continuación hacemos una copia de la imagen y calculamos sus momentos invariantes

#+BEGIN_SRC python
lle = ll
bound = lambda x: 255 if x > 200 else 1
lle.map_over(lambda r, g, b: (bound(g), bound(g), bound(g)))
lle.show()
print(ll.hu_moments())
#+END_SRC

#+attr_latex: :width 5cm
[[./images/showbn.png]]

Como resultado obtenemos: =(0.29768184782794443, 0.021067187247205375)=.
Realizaremos este proceso de forma iterativa para cada una de las imágenes de
prueba, para esto desarrollamos las funciones  binarize y get_moments.

#+BEGIN_SRC python
def binarize_(url):
    ll = Image()
    ll.load_file(url)
    ll.map_over(lambda r, g, b: (bound(b), bound(b), bound(b)))
    return ll

binary_leafs = map(binarize_, leafs)
hu_moments = list(map(lambda x: x.hu_moments(), binary_leafs))

def get_moments(url):
    im = Image()
    im.load_file(url)
    return ("  "+url.split("/")[3].split(".")[0], im.hu_moments())

get_position = lambda x: x[1]
#+END_SRC

De este modo podremos visualizar la distribución de los momentos invariantes de
las imágenes en el plano.

#+BEGIN_SRC python
hu_name_moments = list(map(get_moments, leafs))
plt.scatter(*zip(*hu_moments))
for label, moments in hu_name_moments:
    plt.annotate(label, moments)
url, moments = get_moments(leafs[1])
plt.show()
#+END_SRC

#+attr_latex: :width 10cm
[[./images/plano.png]]

Ahora cargamos la imagen de prueba que usaremos

#+BEGIN_SRC python
test = "./testimages/leafs/test3.jpg"
testimage = Image()
testimage.load_file(test)
testimage.show()
#+END_SRC

#+attr_latex: :width 5cm
[[./images/test.png]]

Convertimos la imagen a blanco y negro

#+BEGIN_SRC python
testimage.black_white().show()

#+END_SRC

#+attr_latex: :width 5cm
[[./images/testbn.png]]

Y obtenemos su histograma

#+BEGIN_SRC python
hist_normal = testimage.histogram()
plt.plot(hist_normal, 'g')
plt.show()
#+END_SRC

#+attr_latex: :width 10cm
[[./images/hist.png]]

Calculamos el valor t que minimiza la varianza

#+BEGIN_SRC python
t = testimage.minimum_otsu()
print(t)

134
#+END_SRC

Y lo usamos para binarizar la imagen

#+BEGIN_SRC python
image = testimage.copy()
image.binarize(t).show()
#+END_SRC

#+attr_latex: :width 5cm
[[./images/testbin.png]]

Calculamos los momentos de Hu de la imagen

#+BEGIN_SRC python
hm = image.hu_moments()
print(hm)
#+END_SRC

Y obtenemos =(0.3601956207386796, 0.010512156197008187)=. Seguidamente agregamos
la imagen a la gráfica para comprobar sus cercanía con otros valores.

#+BEGIN_SRC python
hu_moments = list(map(get_position, hu_name_moments))
tm = ("imagen de prueba", hm)

plt.scatter(*zip(*hu_moments))
for label, moments in hu_name_moments:
    plt.annotate(label, moments)
plt.scatter(*hm)
plt.annotate(*tm)
url, moments = get_moments(leafs[1])
plt.show()
#+END_SRC

#+attr_latex: :width 10cm
[[./images/result.png]]

Finalmente comprobamos que a simple vista, los momentos invariantes calculados
para la imagen de prueba se encuentran cercanas a los momentos de la hoja de
forma ovada, que es la forma que le corresponde.

* Conclusiones y observaciones
Aunque la imagen de prueba se encuentra más cercana al valor esperado que a
otros, esto no garantiza que este siempre vaya a ser el caso, o que dos imágenes
diferentes tengan momentos invariantes similares. La recolección de más imágenes
de prueba y el tratamiento estadístico apropiado de sus resultados, serían los
pasos a seguir para obtener mejores resultados, además de la aplicación de un
algoritmo de clasificación como k-nearest neighbors que se describió brevemente
en este trabajo.

\newpage

\bibliographystyle{apalike}
\bibliography{report}

\newpage

* Anexos
** Código fuente
Este es el contenido de la biblioteca =image= desarrollada para manipular
imágenes con comodidad e implementar los diferentes métodos de procesamiento de
imágenes usados en este proyecto.

#+include: ../image.py src python

* Footnotes

[fn:wightvariance] Traducido de /weighted within-class variance/.

[fn:centroide] Centro de gravedad.

[fn:spread-slenderness] Traducido de /spread/ y /slenderness/ en el artículo original.
